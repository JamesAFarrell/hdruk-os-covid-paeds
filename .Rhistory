#type = "partitional",
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
series[1]
series2 = series %>% map(function(series){series[1:5]})
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
series2 = series %>% map(function(series){series[1:100]})
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
library(lcmm)
# Load packages ----
library(tidyverse)
library(dtwclust)
library(peakRAM)
# Reinterpolate to same length
series <- reinterpolate(CharTraj, new.length = max(lengths(CharTraj)))
# Subset for speed
series <- rep(series, 10)
series2 = series %>% map(function(series){series[1:100]})
# Making many repetitions
peakRAM(
ts_model <- tsclust(series, k = 4L,
seed = 3247, trace = TRUE,
distance = "sdtw",
type = "partitional",
window.size = 50,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
sample(100:200, 1)
series2 = series %>% map(function(series){series[1:sample(100:200, 1)]})
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "lbk",
type = "partitional",
window.size = 50,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "sbd",
type = "partitional",
window.size = 50,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
ts_model@cluster
ts_model@converged
ts_model@family
defaultNumThreads()
RcppParallel::defaultNumThreads()
?partitional_control
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
window.size = NULL,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
window.size = 5,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "sbd",
type = "partitional",
#window.size = 5,
control = partitional_control(
pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "sbd",
type = "partitional",
#window.size = 5,
#control = partitional_control(
#  pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "sbd",
type = "partitional"#,
#window.size = 5,
#control = partitional_control(
#  pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional"#,
#window.size = 5,
#control = partitional_control(
#  pam.precompute = FALSE,
#  pam.sparse = TRUE
)
)
?doParallel::makeCluster
?makeCluster
# Reinterpolate to same length
series <- reinterpolate(CharTraj, new.length = max(lengths(CharTraj)))
# Subset for speed
series <- rep(series, 50)
series2 = series %>% map(function(series){series[1:sample(100:200, 1)]})
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional",
#window.size = 5,
control = partitional_control(
pam.precompute = FALSE#,
#  pam.sparse = TRUE
)
)
)
# Making many repetitions
peakRAM(
ts_model <- tsclust(series2, k = 4L,
seed = 3247, trace = TRUE,
distance = "dtw_basic",
type = "partitional"#,
#window.size = 5,
#control = partitional_control(
# pam.precompute = FALSE#,
#  pam.sparse = TRUE
)
)
CharTraj
x = CharTraj
View(x)
# Studying the Long-term Impact of COVID-19 in Kids (SLICK)
#
# 11_DTW_tsclust.R
# Centre for Medical Informatics, Usher Institute, University of Edinburgh 2022
# School of Informatics, University of Edinburgh 2022
# Written by: Karthik Mohan, James Farrell
#
# This script determines patient clusters based on time series clustering of
# healthcare resource use during the follow-up period.
print("000")
# Load packages ----
library(tidyverse)
print("001")
library(lubridate)
print("002")
library(dtwclust)
print("003")
library(tictoc)
print("004")
# Load function files ----
source(here::here("analysis", "11_0_DTW_functions.R"))
print("005")
# Command arguments to set number of clusters ----
args = commandArgs(trailingOnly=TRUE)
if(length(args) == 0){
n_clusters = 5
} else{
n_clusters = args[[1]] %>% as.integer()
}
print("006")
# Load data ----
data_timeseries_dtw = read_rds(here::here("output", "data", "data_timeseries_dtw.rds"))
print("007")
# Create output directories ----
dir.create(here::here("output", "dtw", "tsclust"),      showWarnings = FALSE, recursive=TRUE)
dir.create(here::here("output", "dtw", "cv_indicies"),  showWarnings = FALSE, recursive=TRUE)
dir.create(here::here("output", "dtw", "data_cluster"), showWarnings = FALSE, recursive=TRUE)
print("008")
lengths(data_timeseries_dtw)
# Load packages ----
library(tidyverse)
library(lubridate)
library(finalfit)
# Load custom functions and lookup tables ----
source(here::here("analysis", "00_utility_functions.R"))
# Output directories ----
dir.create(here::here("output", "data"),
showWarnings = FALSE, recursive=TRUE)
dir.create(here::here("output", "descriptives", "positive_cohort"),
showWarnings = FALSE, recursive=TRUE)
# Load global variables ----
global_var = jsonlite::read_json(path = here::here("analysis", "global_variables.json"))
# Study dates ----
study_start_date = ymd(global_var$start_date)
study_end_date   = ymd(global_var$end_date)
tp_start_date    = ymd(global_var$tp_start_date)
tp_end_date      = ymd(global_var$tp_end_date)
fup_start_date   = ymd(global_var$fup_start_date)
# Random sample ----
set.seed(4192875)
n_positive_sample = 50000
# Load patient data ----
data_patient    = read_rds(here::here("output", "data", "data_patient.rds"))
# Calculate time dependendt variables on test date
# (age, comorbidity, vaccination, death)
data_patient = data_patient %>%
calc_indexed_variables(data_patient %>% pull(covid_test_date_pos_tp))
# Calculate follow-up/censor dates, duration and events -----
data_patient = data_patient %>%
mutate(
follow_up_start_date = covid_test_date_pos_tp + days(15),
max_follow_up_end_date = follow_up_start_date + days(364),
censor_date = pmin(study_end_date,
max_follow_up_end_date,
death_date,
na.rm = TRUE),
censor_event = case_when(
censor_date == max_follow_up_end_date ~ "Maximum follow-up duration",
censor_date == study_end_date ~ "Study end",
censor_date == death_date ~ "Died",
),
follow_up_days = (censor_date - follow_up_start_date) %>%
as.numeric()
)
# Create inclusion flowchart data ----
data_inclusion = data_patient %>%
transmute(
patient_id,
tested_positive = covid_status_tp == "Positive",
not_nosocomial = covid_nosocomial == "No",
no_discrepant_results = covid_discrepant_test == "No",
age_between_4_and_17 = (age >= 4) & (age < 18),
alive_on_test_date = death == "No",
minimum_90_days_follow_up = follow_up_days >= 90
) %>%
replace_na(
list(age_between_4_and_17 = FALSE,
minimum_90_days_follow_up = FALSE))
# Randomly sample from patients satisfying inclusion ----
random_sample = data_inclusion %>%
pivot_longer(-patient_id) %>%
group_by(patient_id) %>%
summarise(elegible_for_sample = all(value)) %>%
filter(elegible_for_sample) %>%
slice_sample(n = min(n_positive_sample, nrow(.)), replace = FALSE) %>%
mutate(randomly_sampled = TRUE)
data_inclusion = data_inclusion %>%
left_join(random_sample %>%
select(patient_id, randomly_sampled), by = "patient_id") %>%
replace_na(list(randomly_sampled = FALSE))
# Create inclusion flowchart ----
flowchart = data_inclusion %>%
transmute(
patient_id,
c0 = TRUE,
c1 = c0 & tested_positive,
c2 = c1 & not_nosocomial,
c3 = c2 & no_discrepant_results,
c4 = c3 & alive_on_test_date,
c5 = c4 & age_between_4_and_17,
c6 = c5 & minimum_90_days_follow_up,
c7 = c6 & randomly_sampled
) %>%
select(-patient_id) %>%
summarise(across(.fns=sum)) %>%
mutate(pivot_col = "pivot") %>%
pivot_longer(
cols=-pivot_col,
names_to="criteria",
values_to="n"
) %>%
select(-pivot_col) %>%
mutate(
n = n #%>% plyr::round_any(count_round)
) %>%
mutate(
n_exclude = lag(n) - n,
pct_all = (n/first(n)) %>% scales::percent(0.1),
pct_exclude_step = (n_exclude/lag(n)) %>% scales::percent(0.1),
crit = str_extract(criteria, "^c\\d+"),
criteria = fct_case_when(
crit == "c0" ~ "OpenSAFELY extract: Registered with GP, alive, with age >0 and <18 years on 01 January 2019",
crit == "c1" ~ "-  Positive SARS-CoV-2 RT-PCR test during testing period",
crit == "c2" ~ "-  with no probable nosocomial infection",
crit == "c3" ~ "-  with no same-day discrepant RT-PCR test result",
crit == "c4" ~ "-  alive on test date",
crit == "c5" ~ "-  with age between 4 and 17 years inclusive on test date",
crit == "c6" ~ "-  with minimum 90 days follow-up",
crit == "c7" ~ "-  randomly sampled",
TRUE ~ NA_character_
)
) %>%
mutate(n_exclude = n_exclude %>% as.character()) %>%
replace_na(
list(n_exclude = "-", pct_exclude_step = "-")
)
## Format flowchart table ----
tbl_flowchart = flowchart %>%
select(criteria, n, n_exclude, pct_all, pct_exclude_step)
## Save flowchart table ----
write_csv(tbl_flowchart,
here::here("output", "descriptives", "positive_cohort",
"tbl_flowchart.csv"))
# Create inclusion flag and append to patient data ----
data_patient = data_patient %>%
left_join(data_inclusion %>%
pivot_longer(-patient_id) %>%
group_by(patient_id) %>%
summarise(include_flag = all(value)),
by = "patient_id")
# Create positive cohort based on inclusion flag ----
data_positives = data_patient %>%
filter(include_flag)
# Load resource data and filter patient id ----
data_admissions = read_rds(here::here("output", "data", "data_admissions.rds")) %>%
filter(patient_id %in% data_positives$patient_id)
data_outpatient = read_rds(here::here("output", "data", "data_outpatient.rds")) %>%
filter(patient_id %in% data_positives$patient_id)
data_gp = read_rds(here::here("output", "data", "data_gp.rds"))  %>%
filter(patient_id %in% data_positives$patient_id)
# Filter out specialty specific/non-contact code types ----
data_outpatient = data_outpatient %>%
filter(is.na(specialty))
data_gp = data_gp %>%
filter(str_starts(code_type, "KM_") |
str_starts(code_type, "mapped_1_") |
str_starts(code_type, "mapped_2"))
# Resource dataset ----
## Create template spanning 1 year prior to positive test to censor date ----
data_resource = data_positives %>%
group_by(patient_id) %>%
summarise(
date = seq(covid_test_date_pos_tp - days(365), censor_date, "day"),
date_indexed = (date - covid_test_date_pos_tp) %>%
as.numeric() %>%
ff_label("Day relative to index positive test date")
) %>%
ungroup()
## Bed-days ----
data_resource = data_resource %>%
left_join(
data_admissions %>%
select(patient_id, admission_date, discharge_date) %>%
rowwise() %>%
mutate(date = list(seq(admission_date, discharge_date, by = "day"))) %>%
unnest(date) %>%
ungroup() %>%
mutate(
n_beddays = case_when(
date == admission_date ~ 0.5,
date == discharge_date ~ 0.5,
TRUE ~ 1)
) %>%
group_by(patient_id, date) %>%
summarise(n_beddays = min(sum(n_beddays), 1)) %>%
ungroup(),
by = c("patient_id", "date")
) %>%
replace_na(list(n_beddays = 0))
## Critical-care ----
data_resource = data_resource %>%
left_join(
data_admissions %>%
filter(critical_care_days > 0) %>%
select(patient_id, index, admission_date, discharge_date, critical_care_days) %>%
rowwise() %>%
mutate(date = list(seq(admission_date,
min(admission_date + days(critical_care_days), discharge_date),
by = "day"))) %>%
unnest(date) %>%
group_by(patient_id, index) %>%
mutate(
critical_care_days = case_when(
row_number() == 1 ~ 0.5,
row_number() == n() ~ 0.5,
TRUE ~ 1
)
) %>%
group_by(patient_id, date) %>%
summarise(
n_critical_care = min(sum(critical_care_days), 1)
),
by = c("patient_id", "date")
) %>%
replace_na(list(n_critical_care = 0))
## Outpatient ----
data_resource = data_resource %>%
left_join(
data_outpatient %>%
group_by(patient_id, outpatient_date) %>%
summarise(
n_outpatient = sum(outpatient_count)
) %>%
rename(date = outpatient_date),
by = c("patient_id", "date")
) %>%
replace_na(list(n_outpatient = 0))
## GP ----
data_resource = data_resource %>%
left_join(
data_gp %>%
group_by(patient_id, gp_date) %>%
summarise(
n_gp = 1
) %>%
rename(date = gp_date),
by = c("patient_id", "date")
) %>%
replace_na(list(n_gp = 0))
# Positive test period -----
data_positives = data_positives %>%
mutate(
covid_test_date_period = covid_test_date_pos_tp %>%
floor_date(unit = "3 months")
)
data_positives$covid_test_date_period
ymd("2020-01-01") %>%
floor_date(unit = "3 months")
ymd("2020-02-01") %>%
floor_date(unit = "3 months")
ymd("2020-03-01") %>%
floor_date(unit = "3 months")
ymd("2020-03-31") %>%
floor_date(unit = "3 months")
ymd("2020-05-31") %>%
floor_date(unit = "3 months")
?binomial
